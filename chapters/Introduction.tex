\chapter{Introduction}
Lossless data compression has the ability to reduce storage requirements, while still maintaining the integrity of the original data.
Several advantages can be gained by reducing the size of data, including the relief of transfer accoss I/O channels.
Compression algorithms have a tradeoff, in that they require an additional computation to be done on the original data before a compressed version can be used.
This can be computationally expensive and the cost to compress might require too much processing or time.
In many cases and applications, the increase of bandwidth rates outweighs any other consideration, but the increase in compression rates would generally be helpful.
This work takes a look into speeding up those compression rates by performing the compression directly on a GPU, a graphics processing unit.

An increase of applications and algorithms are being developed to utilize the relatively new general purpose computing (GPGPU) apsect of GPU technology.
GPGPUs allow applications to run computations unrelated to graphics, while allowing for the exploitation of the massively parallel nature of GPUs.
GPGPUs are becoming increasingly popular for high performance computing, and many of the world's fastest supercomputers utilize GPGPUs in large clusters.

GPGPU as coprocessor
GPGPU massively parallel
difference vs CPU

Thesis statement
Organization
